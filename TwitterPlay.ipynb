{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(minglbot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<module 'minglbot' from 'minglbot.pyc'>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import logging #see http://docs.python.org/2/howto/logging\n",
      "import tweepy\n",
      "from Queue import PriorityQueue\n",
      "import minglbot\n",
      "\n",
      "m = minglbot.MinglBot(os.getenv(\"TWITTER_CONSUMER_KEY\"), os.getenv(\"TWITTER_CONSUMER_SECRET\"))\n",
      "class Job(object):\n",
      "    def __init__(self,id,screen_names,author):\n",
      "        self.id = id\n",
      "        self.screen_names = screen_names\n",
      "        self.author = author\n",
      "        \n",
      "    def __repr__(self):\n",
      "        return \"{0}:{1}:{2}\".format(self.id,','.join(self.screen_names),self.author)\n",
      "\n",
      "class JobQueue(object):\n",
      "    def __init__(self):\n",
      "        self._priorityQueue = PriorityQueue()\n",
      "    \n",
      "    def put(self,job,priority_metric):\n",
      "        self._priorityQueue.put_nowait((-priority_metric,job))\n",
      "        \n",
      "    def get(self):\n",
      "        try:\n",
      "            return self._priorityQueue.get_nowait()[1]\n",
      "        except Exception:\n",
      "            return None\n",
      "    \n",
      "    def __iter__(self):\n",
      "        job = True\n",
      "        while job:\n",
      "            job = self.get()\n",
      "            yield job\n",
      "        \n",
      "class TwitterBot(object):\n",
      "    def __init__(self,\n",
      "                 twitter_consumer_key,\n",
      "                 twitter_consumer_secret,\n",
      "                 bot_screen_name = \"minglbot\",\n",
      "                 response_history_file=\"response_history.txt\",\n",
      "                 twitter_bot_token=None,\n",
      "                 twitter_bot_secret=None):\n",
      "        logging.basicConfig(filename=\"twitterbot.log\",level=logging.INFO)\n",
      "        logging.info(\"Initializing TwitterBot\")\n",
      "        twitter_bot_token = twitter_bot_token if twitter_bot_token else os.getenv(\"TWITTER_BOT_TOKEN\")\n",
      "        twitter_bot_secret = twitter_bot_secret if twitter_bot_secret else os.getenv(\"TWITTER_BOT_SECRET\")\n",
      "        auth = tweepy.OAuthHandler(twitter_consumer_key, twitter_consumer_secret)\n",
      "        auth.set_access_token(twitter_bot_token, twitter_bot_secret)\n",
      "        self._twitter = tweepy.API(auth)\n",
      "        self._screen_name = bot_screen_name.lower()\n",
      "        self._response_history_file = response_history_file\n",
      "        self._minglbot = minglbot.MinglBot(os.getenv(\"TWITTER_CONSUMER_KEY\"), os.getenv(\"TWITTER_CONSUMER_SECRET\"))\n",
      "        self._job_queue = JobQueue()\n",
      "        self._since_id = 1 #message status id to start with. by default start reading from the beginning of time\n",
      "        self._min_screen_names = 3 #TODO change this to like 6 or so\n",
      "        try:\n",
      "            with open(response_history_file) as f:\n",
      "                done_job_ids = [int(line.strip()) for line in f]\n",
      "        except IOError, e:\n",
      "            logging.fatal(\"trouble opening response_history.txt: {0}\".format(e))\n",
      "            exit(1)\n",
      "        self._done_job_iter = iter(done_job_ids)\n",
      "        self._done_job_id = 0\n",
      "        \n",
      "    def _refresh_jobs(self):\n",
      "        mentions = self._twitter.mentions_timeline(since_id=self._since_id,count=800)\n",
      "        for mention in mentions:\n",
      "            if self._done_job_id > mention.id:\n",
      "                screen_names = []\n",
      "                for user in mention.entities[\"user_mentions\"]:\n",
      "                    screen_name = user[\"screen_name\"].lower()\n",
      "                    if screen_name != self._screen_name:\n",
      "                        screen_names.append(screen_name)\n",
      "                if len(screen_names) > self._min_screen_names:\n",
      "                    self._job_queue.put(\n",
      "                        Job(mention.id, screen_names, mention.author.screen_name.lower()),\n",
      "                        mention.author.followers_count\n",
      "                    )\n",
      "            while self._done_job_id <= mention.id:\n",
      "                try:\n",
      "                    self._done_job_id = self._done_job_iter.next()\n",
      "                except StopIteration:\n",
      "                    self._done_job_id = float(\"inf\")\n",
      "        self._since_id = mention.id\n",
      "        \n",
      "    def _execute_job(self):\n",
      "        job = self._job_queue.get()\n",
      "        if not job:\n",
      "            return False\n",
      "        logging.info(u\"Executing job: {0}\".format(job))\n",
      "        \n",
      "        #get mutual friends, hydrate, and then retrieve them again from Neo4J\n",
      "        #the reason for the double retrieval is that the hydration throws away the ordering and grouping\n",
      "        friends = self._minglbot.get_mutual_friends(job.screen_names)\n",
      "        m.hydrate_users(friends)\n",
      "        friends = self._minglbot.get_mutual_friends(job.screen_names)\n",
      "        \n",
      "        #get only the friends that about half of them know\n",
      "        popularity = len(job.screen_names)/2\n",
      "        if popularity < 3:\n",
      "            popularity = 3\n",
      "        friends = friends.get_all_with_min_popularity(popularity)\n",
      "        if len(friends) > 3:\n",
      "            tweet = \"@{0}, their best friends:\".format(job.author)\n",
      "            for friend in friends:\n",
      "                if len(tweet)<=140:\n",
      "                    tweet += \" @\"+friend.screen_name\n",
      "        else:\n",
      "            tweet = \"@{0}, these users don't seem to have much in common\".format(job.author)\n",
      "        logging.info(\"sending tweet: \"+tweet)\n",
      "#        self._twitter.update_status(tweet,job.id)\n",
      "        with open(self._response_history_file,'a') as f:\n",
      "            f.write(\"{0}\\n\".format(job.id))\n",
      "    \n",
      "        #do job\n",
      "                #X immediate friends\n",
      "                #central figures\n",
      "                #group self description\n",
      "                #how you can connect\n",
      "        return True\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t=TwitterBot(os.getenv(\"TWITTER_CONSUMER_KEY\"), os.getenv(\"TWITTER_CONSUMER_SECRET\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t._refresh_jobs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t._execute_job()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = mentions[0]\n",
      "print dir(m)\n",
      "print \"author id:\", m.author.id\n",
      "print \"author screen_name:\",m.author.screen_name\n",
      "print \"text:\", m.text\n",
      "print \"entities:\", m.entities\n",
      "for u in m.entities[\"user_mentions\"]:\n",
      "    print \"\\t\",u[\"id\"],u[\"screen_name\"]\n",
      "print \"id:\", m.id\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__getstate__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', 'author', 'contributors', 'coordinates', 'created_at', 'destroy', 'entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'lang', 'parse', 'parse_list', 'place', 'possibly_sensitive', 'retweet', 'retweet_count', 'retweeted', 'retweets', 'source', 'source_url', 'text', 'truncated', 'user']\n",
        "author id: 292737115\n",
        "author screen_name: treygrainger\n",
        "text: @JnBrymn Similar foreground/background concept, yes. What I showed in http://t.co/0dEDpLMZhI ranks terms in a doc vs. whole index, though.\n",
        "entities: {u'symbols': [], u'user_mentions': [{u'id': 28881634, u'indices': [0, 8], u'id_str': u'28881634', u'screen_name': u'JnBrymn', u'name': u'John Berryman'}], u'hashtags': [], u'urls': [{u'url': u'http://t.co/0dEDpLMZhI', u'indices': [70, 92], u'expanded_url': u'http://www.treygrainger.com/posts/presentations/enhancing-relevancy-through-personalization-semantic-search/', u'display_url': u'treygrainger.com/posts/presenta\\u2026'}]}\n",
        "\t28881634 JnBrymn\n",
        "id: 455064379227402240\n"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#trash below here"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.screen_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "[u'o3design', u'ustream']"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minglbot.MinglBot._split_up_input(j.screen_names,{int:\"ids\",basestring:\"screen_names\"})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "defaultdict(<type 'list'>, {'screen_names': [u'o3design', u'ustream']})"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"asdf\"!=\"asdf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t._twitter.update_status(\"nite folks\",455488257305088000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<tweepy.models.Status at 0x102341310>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}